{
  "hash": "a69abac86d3c2596ec76c008559e97b5",
  "result": {
    "engine": "knitr",
    "markdown": "# Cross Validation {#sec-cv}\n\n## Data preparation {#sec-cv-prep}\n\n### Internal validation cohort {#sec-cv-prep-int-val}\n\nInternal validation dataset was from the `Validation` dataset shown in @fig-fig1 C. \n\nNow we set up the `Salmon` quant files of the validation (i.e. term) dataset. NB, `dt.colllDataAll` (shown from the code below) was set up from @lst-prep-quant-sf.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to set the `Salmon` quant files of the term dataset (i.e. Validation dataset)\"}\n# remove these two samples as both of them flagged as \"failed\" by illumina (it is a 28wk control sample)\ndt.colDataTerm<-dt.colDataAll[Type==\"term\" & !names %in% c(\"GS-B-374-UW\",\"GS-B-374-UW-b\")] \nli.GA.term<-split(dt.colDataTerm, dt.colDataTerm$GA)\n```\n:::\n\n\nWe are ready to read the `Salmon` quant files via `tximeta` R package. NB, the code below is equivalent to @lst-prep-dds and @lst-set-dds from the discovery cohort (see @sec-mtd-deg-deseq2).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to read the `Salmon` quant files of the term dataset and make `dds` object.\"}\nmy.dds.RData<-paste0(\"RData/dds.term.\",my.salmon.index,\".RData\")\nif(file.exists(my.dds.RData)){\n  load(my.dds.RData)\n  message(\"loading dds...\")\n}else{\n  gse.term<-tximeta::tximeta(dt.colDataTerm,skipMeta=T,tx2gene=dt.tx2gene[,.(transcript_id,gene_id)],txOut=F)\n  # set up `dds` at gene-level\n  my.design <- formula(~ Batch + GA + Sex + Condition) \t\t# isa 'formula'\n  dds.term <- DESeqDataSet(se=gse.term, design=my.design) \n\n  dds.term$Group<-factor(paste0(dds.term$GA,dds.term$Condition)) # add 'Group'\n  design(dds.term) <- formula(~ Batch + Sex + Group) \t\t# isa 'formula'\n\n  #\n  dds.term<- DESeq(dds.term, parallel=TRUE) # isa 'DESeqDataSet'\n  save(dds.term,file=my.dds.RData)\n}\n\n# use 15150 genes considered in this study\ndds.f2.term<-DESeq(dds.term[rownames(dds.f2)], parallel=T)\n\nmy.dl.resLFC.RData<-paste0(\"RData/dl.resLFC.term.\",my.salmon.index,\".RData\")\nif(file.exists(my.dl.resLFC.RData)){\n  load(my.dl.resLFC.RData)\n}else{\n  # apply shink\n  li.resLFC.term<-lapply(names(li.GA.term),function(my.GA){\n    my.res<-results(dds.f2.term, \n            #alpha=.05, # by default independant filtering at FDR (alpha) 0.1 (10%) \n            independentFiltering=FALSE,\n            lfcThreshold=log2(minFC), \n            contrast=c(\"Group\",paste0(my.GA,c(\"Case\",\"Control\"))),\n            parallel=TRUE)  \n    lfcShrink(dds.f2.term, \n              #contrast=c(\"Group\",paste0(my.GA,c(\"Case\",\"Control\"))), # not necessary for 'ashr'\n              res=my.res, #li.res[[my.GA]],\n              lfcThreshold=log2(minFC), # not applicable for 'asher' \n              type=\"ashr\",\n              parallel=TRUE)  \n  })\n  names(li.resLFC.term)<-names(li.GA.term)\n\n  dl.resLFC.term<-lapply(li.resLFC.term, function(i)\n    data.table(`gene_id`=rownames(i), as.data.frame(i))[order(pvalue)][,`:=`(\"BH\"=p.adjust(pvalue,\"BH\"),\"BY\"=p.adjust(pvalue,\"BY\"),\"bf\"=p.adjust(pvalue,\"bonferroni\"))]\n  )\n  save(dl.resLFC.term, file=my.dl.resLFC.RData)\n  #fwrite(dl.resLFC[[\"28wk\"]], file=paste0(\"data/DEG.DSeq2.28wk.\",my.type,\".\",my.salmon.index,\".csv\"))\n}\n```\n:::\n\n\nNow we use `edgeR`. NB, this is equivalent to @lst-set-edger shown in @sec-mtd-deg-edger.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to find DEGs by `edgeR` from the term dataset\"}\ngse2 <-gse.term[rownames(dds.f2.term),]\nd2<-tximeta::makeDGEList(gse2)\nd2$samples<-cbind(d2$samples,colData(gse2))\nd2$samples$group<-factor(paste0(d2$samples$GA,d2$samples$Condition)) # add 'group'\nd2$samples$GA<-droplevels(d2$samples$GA) # 36wk removed - really? 2023-03-21\nd2$samples$Batch<-droplevels(d2$samples$Batch) # some batches removed\n\n# TMM normalisation (default). It adds `norm.factors` d2$samples\n# NB, we have `offsets`, which take precedence over lib.size and norm.factors\nd2<-calcNormFactors(d2,method=\"TMM\") \n\n# design\n# my.design <- model.matrix(~ Batch + Sex + group, data=d2$samples) \t\t# isa 'matrix'\n#my.design <- model.matrix(~ 0 + group,  data=d2$samples) \t\t# isa 'matrix'\nmy.design <- model.matrix(~ 0 + group + Sex + Batch , data=d2$samples) \t\t# isa 'matrix'\n(my.contrasts <- makeContrasts(`12wk`=group12wkCase-group12wkControl, \n                              `20wk`=group20wkCase-group20wkControl, \n                              `28wk`=group28wkCase-group28wkControl, \n                              levels=my.design)\n)\n\n# dispersion\n#dp2 = estimateDisp(d2, design=my.design, verbose=T)\ndp2 = estimateGLMCommonDisp(d2, design=my.design, verbose=T) \ndp2 = estimateGLMTrendedDisp(dp2, design=my.design, verbose=T)\ndp2 = estimateGLMTagwiseDisp(dp2, design=my.design)\n\n#f = glmFit(dp2, design=my.design) # \nf = glmQLFit(dp2, design=my.design) # QL(Quasi-like) pipeline\ncolnames(f)\nf$coefficients %>% head\n\n# get the edgeR results\nli.res.edgeR.term<-lapply(names(li.GA.term), function(i){\n  te <- glmTreat(f, contrast=my.contrasts[,i], lfc=log2(minFC))\n  topTags(te, n=nrow(te))    # default sort by pvalue\n})\nnames(li.res.edgeR.term) <-names(li.GA.term)\n\ndl.res.edgeR.term<-lapply(li.res.edgeR.term, function(i)\n  data.table(`gene_id`=rownames(i),i$table)[order(PValue)][,`:=`(\"BH\"=p.adjust(PValue,\"BH\"),\"BY\"=p.adjust(PValue,\"BY\"),\"bf\"=p.adjust(PValue,\"bonferroni\"))]\n)\n\nmy.dl.res.edgeR.RData<-paste0(\"RData/dl.res.edgeR.term.\",my.salmon.index,\".RData\")\nsave(dl.res.edgeR.term, file=my.dl.res.edgeR.RData)\n#fwrite(dl.res.edgeR[[\"28wk\"]], file=paste0(\"data/DEG.edgeR.28wk.\",my.type,\".\",my.salmon.index,\".csv\"))\n```\n:::\n\n\nThe gene-level count matrix was converted as the unit of CPM (Count Per Million), in log2-scale, via the “cpm” function of edgeR and it was further transformed into a matrix of the z-score using the mean and standard deviation of logCPM from the control samples of each corresponding gestational age group. NB, this is equivalent to @lst-cnt-cpm shown in @sec-zscore-mat.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make the count matrix from the validation dataset\"}\n# based on genes from dds.f2.term\n# CPM based on edgeR TMM  (NB, d isa \"DGEList\")\nmy.cnt.RData<-paste0(\"RData/dt.count2.term.\",my.salmon.index,\".RData\")\nif(file.exists(my.cnt.RData)){\n  load(my.cnt.RData)\n}else{\n  dt.count<-merge(\n    data.table(`geneName`=rownames(dds.f2.term),counts(dds.f2.term,normalized=T)) %>% \n      melt.data.table(id.vars=c(\"geneName\"),variable.name=\"SampleID\",value.name=\"Count\"),\n    dt.samples[Type==\"term\",.(SampleID,GA,Condition,Group=paste(GA,Condition,sep=\"-\"))]\n  )\n\n  # CPM based on DESeq2 `fpm`\n  dt.cpm<-merge(\n    data.table(`geneName`=rownames(dds.f2.term),fpm(dds.f2.term)) %>% \n      melt.data.table(id.vars=c(\"geneName\"),variable.name=\"SampleID\",value.name=\"CPM\"),\n    dt.samples[Type==\"term\",.(SampleID,GA,Condition,Group=paste(GA,Condition,sep=\"-\"))]\n  )\n\n  dt.tpm<-merge(\n    data.table(`geneName`=rownames(dds.f2.term), assays(dds.f2.term)[[\"abundance\"]]) %>% \n      melt.data.table(id.vars=c(\"geneName\"),variable.name=\"SampleID\",value.name=\"TPM\"),\n    dt.samples[Type==\"term\",.(SampleID,GA,Condition,Group=paste(GA,Condition,sep=\"-\"))]\n  )\n\n  # CPM based on edgeR TMM  (NB, d isa \"DGEList\")\n  dt.cpm2<-merge(\n    data.table(`geneName`=rownames(d2),cpm(d2)) %>% \n      melt.data.table(id.vars=c(\"geneName\"),variable.name=\"SampleID\",value.name=\"CPM\"),\n    dt.samples[Type==\"term\",.(SampleID,GA,Condition,Group=paste(GA,Condition,sep=\"-\"))]\n    )\n\n  dt.logcpm2<-merge(\n    data.table(`geneName`=rownames(d2),cpm(d2,log=T)) %>% \n      melt.data.table(id.vars=c(\"geneName\"),variable.name=\"SampleID\",value.name=\"logCPM\"),\n    dt.samples[Type==\"term\",.(SampleID,GA,Condition,Group=paste(GA,Condition,sep=\"-\"))]\n    )\n\n  save(dt.count, dt.cpm, dt.tpm, dt.cpm2, dt.logcpm2, file=my.cnt.RData)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make the z-score matrix from the validation dataset\"}\nmy.cpmZ.RData<-paste0(\"RData/dt.cpmZ.term.\",my.salmon.index,\".RData\")\nif(file.exists(my.cpmZ.RData)){\n  load(my.cpmZ.RData)\n}else{\n  dt.cpmZ.term=merge(dt.logcpm2,\n                dt.logcpm2[Condition==\"Control\",.(Mean=mean(logCPM),SD=sd(logCPM)),.(GA,geneName)]\n        ,by=c(\"GA\",\"geneName\")\n        )[,.(Group,GA,Condition,SampleID,geneName,logCPM,logCPMZ=(logCPM-Mean)/SD)]\n  save(dt.cpmZ.term,file=my.cpmZ.RData)\n}\n```\n:::\n\n\n### External validation dataset {#sec-cv-prep-ext-val}\n\nFor an external validation, we downloaded the raw sequencing counts file ([Data File S2](https://www.science.org/doi/suppl/10.1126/scitranslmed.aaz0131/suppl_file/aaz0131_data_file_s2.xlsx): Raw whole-transcriptome sequencing counts for iPEC cohort; n=113) from [Munchel et al.](https://pubmed.ncbi.nlm.nih.gov/32611681/). The Data File (in the excel file format) was read and parsed by using [`readxl`](https://readxl.tidyverse.org/) (v1.3.1) and [`data.table`](https://rdatatable.gitlab.io/data.table/) (v1.13.6) R packages, respectively. \n\nFor downstream processing, we only considered those genes in the final set of 15,150 genes that were used in the differentially expressed gene analysis of the discovery and the validation cohort (see @sec-mtd-deg-deseq2). \n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to import Munchel dataset and make `dds` object by `DESeq2`\"}\nmy.dds.RData<-paste0(\"RData/dds.munchel.RData\")\nif(file.exists(my.dds.RData)){\n  load(my.dds.RData)\n  message(\"loading dds...\")\n}else{\n  # import\n  dt.foo<-readxl::read_excel(\"~/data/Munchel/SciTrMed.2020/aaz0131_data_file_s2.xlsx\",skip=3) %>% as.data.table\n  dt.foo[,-c(\"Chr\",\"Start\",\"End\",\"Strand\")][1:5,1:5]\n\n  # sample info with GA of sample collection\n  dt.munchel.meta<-data.table(\n                            names=dt.foo[is.na(Geneid),-c(\"Geneid\",\"Chr\",\"Start\",\"End\",\"Strand\",\"Length\")] %>% \n                              colnames %>% \n                              stringr::str_replace(\"\\\\.\\\\.\\\\.\",\"\"),\n                            GA=dt.foo[is.na(Geneid),-c(\"Geneid\",\"Chr\",\"Start\",\"End\",\"Strand\",\"Length\")] %>% unlist \n                            )\n  dt.munchel.meta[,Condition:=ifelse(grepl(\"PE\",names),\"Case\",\"Control\")]\n  dt.munchel.meta$GA %>% summary\n  dt.munchel.meta[,.N,Condition]\n  dt.munchel.meta[Condition==\"Control\"]$GA %>% summary\n  dt.munchel.meta[Condition==\"Case\"]$GA %>% summary\n  df.munchel.meta<-data.frame(dt.munchel.meta, row.names=dt.munchel.meta$names)\n\n  # cnt \n  dt.munchel.cnt<-dt.foo[!is.na(Geneid),-c(\"Chr\",\"Start\",\"End\",\"Strand\",\"Length\")]\n  dt.munchel.cnt %>% dim # 26708 genes x 114 samples\n  dt.munchel.cnt[1:5,1:5]\n  colnames(dt.munchel.cnt)<-c(\"gene_name\",dt.munchel.meta$names) # update the sample names\n  dt.munchel.cnt[1:5,1:5]\n  dt.munchel.cnt[,.N,gene_name][N>1][order(-N)] # 0 duplicated gene names \n\n  dt.munchel.cnt[grepl(\"_dup\",gene_name)][,.N,gene_name] # 1355 such gene names\n  dt.munchel.cnt[grepl(\"_dup\",gene_name)][1:5,1:5]\n\n  dt.munchel.cnt[,gene_name:=tstrsplit(gene_name,\"_dup\",fixed=T,keep=1L)]\n  dt.munchel.cnt[grepl(\"_dup\",gene_name)]\n  dt.munchel.cnt[,.N,gene_name][N>1][order(-N)] # 491 duplicated gene names\n  dt.munchel.cnt[gene_name==\"REXO1L2P\",1:5]\n  dt.munchel.cnt[,.N,gene_name %in% rownames(dds.f2)] # genes only in the dds.f2 (15150 genes)\n                                                      # TRUE 13555; FALSE 13153\n  rownames(dds.f2) %in% dt.munchel.cnt$gene_name %>% table # from 15150 genesin dds.f2, 13469 genes in Munchel; 1681 genes not in Munchel\n  dds.f2[!rownames(dds.f2) %in% dt.munchel.cnt$gene_name] %>% names\n\n  dt.munchel.cnt2<- (dt.munchel.cnt[gene_name %in% rownames(dds.f2)] %>% \n                     melt.data.table(id.vars=c(\"gene_name\"), variable.name=\"SampleID\",value.name=\"Cnt\"))[,.(Cnt=sum(Cnt)),.(SampleID,gene_name)] %>% \n                      dcast.data.table(gene_name ~ SampleID, value.var=\"Cnt\")\n  dim(dt.munchel.cnt2) # 13469 genes x 114 samples\n  dt.munchel.cnt2[,.N,gene_name][N>1][order(-N)] # no duplicated genes\n  all.equal(colnames(dt.munchel.cnt),colnames(dt.munchel.cnt2))\n\n  mat.munchel.cnt2<-dt.munchel.cnt2 %>% as.matrix(rownames=\"gene_name\")\n  dim(mat.munchel.cnt2) # 13469 x 113\n  mat.munchel.cnt2[1:5,1:5]\n\n  all.equal(colnames(mat.munchel.cnt2), rownames(df.munchel.meta))\n\n  dds.munchel<-DESeqDataSetFromMatrix(mat.munchel.cnt2, df.munchel.meta, design=formula(~Condition) )\n\n  dds.munchel<- DESeq(dds.munchel, parallel=TRUE) # isa 'DESeqDataSet'\n  save(dt.munchel.meta,dds.munchel,file=my.dds.RData)\n}\n```\n:::\n\n\nUsing the filtered gene-level raw count matrix, we ran edgeR and constructed a matrix of CPM, in log2-scale, via the “cpm” function of edgeR. The matrix was further transformed into a matrix of the z-score using the mean and standard deviation of logCPM from the 73 control samples.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to make the z-score matrix from the Munchel dataset\"}\nmy.cpmZ.RData<-paste0(\"RData/dt.cpmZ.munchel.RData\")\nif(file.exists(my.cpmZ.RData)){\n  load(my.cpmZ.RData)\n}else{\n  load(\"RData/dds.munchel.RData\")\n  dds.munchel # samples from Discovery & Validation1\n\n  d.munchel = DEFormats::as.DGEList(dds.munchel)\n  d.munchel<-calcNormFactors(d.munchel,method=\"TMM\") \n\n  dt.logcpm2<-merge(\n      data.table(`geneName`=rownames(d.munchel),cpm(d.munchel,log=T)) %>% \n        melt.data.table(id.vars=c(\"geneName\"),variable.name=\"SampleID\",value.name=\"logCPM\"),\n      df.munchel.meta,by.x=\"SampleID\",by.y=\"names\"\n      )\n\n  dt.cpmZ.munchel=merge(dt.logcpm2,\n                dt.logcpm2[Condition==\"Control\",.(Mean=mean(logCPM),SD=sd(logCPM)),.(geneName)]\n        ,by=c(\"geneName\")\n        )[,.(Condition,SampleID,geneName,logCPM,logCPMZ=(logCPM-Mean)/SD)]\n  save(dt.cpmZ.munchel,file=my.cpmZ.RData)\n}\n```\n:::\n\n\nNow, it is ready to set up discovery, validation and the external validation dataset:\n\n::: {.cell}\n\n```{#lst-data-setup .r .cell-code  lst-cap=\"Code to setup datset from discovery cohort, validation cohrot, and Munchel\" code-fold=\"true\"}\nload(\"RData/dt.cpmZ.preterm.POPS-2022.GRCh38.88.RData\") # dt.cpmZ (preterm)\nload(\"RData/dt.cpmZ.term.POPS-2022.GRCh38.88.RData\") # dt.cpmZ.term (term)\nload(\"RData/dt.cpmZ.munchel.RData\") # dt.cpmZ.munchel (Munchel)\n\nli.mat<-list()\n# set the train dataset, i.e. preterm-28wk\nli.mat[[\"train\"]]<-lapply(list(`12wk`=\"12wk\",`20wk`=\"20wk\",`28wk`=\"28wk\"), function(my.GA) {\n  dt.cpmZ[GA==my.GA & geneName %in% core17,.(SampleID,geneName,logCPMZ,y=ifelse(Condition==\"Case\",1,0))] %>% dcast.data.table(SampleID+y~geneName,value.var=\"logCPMZ\") %>% as.matrix(rownames=\"SampleID\") # isa 'list'\n  })\n\n# set the test dataset, i.e. term\nli.mat[[\"test\"]]<-lapply(list(`12wk`=\"12wk\",`20wk`=\"20wk\",`28wk`=\"28wk\",`36wk`=\"36wk\"), function(my.GA) {\n    dt.cpmZ.term[GA==my.GA & geneName %in% core17,.(SampleID,geneName,logCPMZ,y=ifelse(Condition==\"Case\",1,0))] %>% dcast.data.table(SampleID+y~geneName,value.var=\"logCPMZ\") %>% as.matrix(rownames=\"SampleID\") # isa 'list'\n  })\n\nli.mat[[\"munchel\"]]<-dt.cpmZ.munchel[geneName %in% core17,.(SampleID,geneName,logCPMZ,y=ifelse(Condition==\"Case\",1,0))] %>% dcast.data.table(SampleID+y~geneName,value.var=\"logCPMZ\") %>% as.matrix(rownames=\"SampleID\") # isa 'matrix'\n```\n:::\n\n\n## Data split for 5-fold CV {#sec-cv-split}\nWe randomly split the samples into 5 strata by distributing the number of case and control outcomes as even as possible across the 5 folds. This stratified 5-fold splitting was repeated 5 times by changing a seed number in each repetition, and the 11 ML models (see below @sec-cv-11ML) were trained to choose a desired number of predictors from 2 to 6. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to split 5-fold with 5 repetitions\"}\n##############################################\n# Set the 5-fold with 5 rep for 28wk preterm #\n##############################################\n# set stratified folds\n# such that the numbers of cases and controls in each fold are the same for each fold (or, at least, as close to this as possible)\nnFold<-5; nRep<-5; li.fold<-list() # index of training in \nfor(iRep in 1:nRep){\n  caseInds <- which(li.mat[[\"train\"]][[\"28wk\"]][,\"y\"]==1)\n  ctrlInds <- which(li.mat[[\"train\"]][[\"28wk\"]][,\"y\"]==0)\n\n  #Randomise for good measure:\n  set.seed(123+iRep)\n  caseInds <- caseInds[sample(1:length(caseInds))]\n  ctrlInds <- ctrlInds[sample(1:length(ctrlInds))]\n\n  approximatelyEqualParts_Cases <- ggplot2::cut_interval(1:length(caseInds), nFold)\n  approximatelyEqualParts_Ctrls <- ggplot2::cut_interval(1:length(ctrlInds), nFold)\n\n  quintiles_Cases <- vector(mode = \"integer\", length = length(caseInds))\n  quintiles_Ctrls <- vector(mode = \"integer\", length = length(ctrlInds))\n  for(i in 1:length(levels(approximatelyEqualParts_Cases))){\n    currentLevel <- levels(approximatelyEqualParts_Cases)[i]\n    quintiles_Cases[approximatelyEqualParts_Cases == currentLevel] <- i\n  }\n\n  for(i in 1:length(levels(approximatelyEqualParts_Ctrls))){\n    currentLevel <- levels(approximatelyEqualParts_Ctrls)[i]\n    quintiles_Ctrls[approximatelyEqualParts_Ctrls == currentLevel] <- i\n  }\n\n  quintiles <- vector(mode = \"integer\", length = nrow(li.mat[[\"train\"]][[\"28wk\"]]))\n  for(i in 1:nFold){\n    quintiles[c(caseInds[quintiles_Cases == i], ctrlInds[quintiles_Ctrls == i])] <- i\n  }\n\n    # Split the data into training and testing sets for this fold\n  for(iFold in 1:nFold){\n    li.fold[[paste0(\"Fold\",iFold,\".Rep\",iRep)]]<-which(quintiles != iFold)\n  }\n} # end of iRep\n\n########################################\n# Set the final 5-fold to use all_28wk #\n########################################\nnFold<-5; nRep<-1; li.fold.final<-list() # index of training in \nfor(iRep in 1:nRep){\n  caseInds <- which(li.mat[[\"train\"]][[\"28wk\"]][,\"y\"]==1)\n  ctrlInds <- which(li.mat[[\"train\"]][[\"28wk\"]][,\"y\"]==0)\n\n  #Randomise for good measure:\n  set.seed(333)\n  caseInds <- caseInds[sample(1:length(caseInds))]\n  ctrlInds <- ctrlInds[sample(1:length(ctrlInds))]\n\n  approximatelyEqualParts_Cases <- ggplot2::cut_interval(1:length(caseInds), nFold)\n  approximatelyEqualParts_Ctrls <- ggplot2::cut_interval(1:length(ctrlInds), nFold)\n\n  quintiles_Cases <- vector(mode = \"integer\", length = length(caseInds))\n  quintiles_Ctrls <- vector(mode = \"integer\", length = length(ctrlInds))\n  for(i in 1:length(levels(approximatelyEqualParts_Cases))){\n    currentLevel <- levels(approximatelyEqualParts_Cases)[i]\n    quintiles_Cases[approximatelyEqualParts_Cases == currentLevel] <- i\n  }\n\n  for(i in 1:length(levels(approximatelyEqualParts_Ctrls))){\n    currentLevel <- levels(approximatelyEqualParts_Ctrls)[i]\n    quintiles_Ctrls[approximatelyEqualParts_Ctrls == currentLevel] <- i\n  }\n\n  quintiles <- vector(mode = \"integer\", length = nrow(li.mat[[\"train\"]][[\"28wk\"]]))\n  for(i in 1:nFold){\n    quintiles[c(caseInds[quintiles_Cases == i], ctrlInds[quintiles_Ctrls == i])] <- i\n  }\n\n    # Split the data into training and testing sets for this fold\n  for(iFold in 1:nFold){\n    li.fold.final[[paste0(\"Fold\",iFold,\".Rep\",iRep)]]<-which(quintiles != iFold)\n  }\n} # end of iRep\n```\n:::\n\n\n## 11 machine learning methods {#sec-cv-11ML}\nWe considered a total of 11 ML methods to select the best performing method based on the 5-fold cross-validation (CV) with 5 repetitions. \n\n![11 machine-learning methods considered in this study](static/figure/cfRNA.11MLr.png){#fig-11ML}\n\nFor the three penalised regression methods (ENet1, ENet2 and LASSO), they were firstly fitted by using the [train](https://topepo.github.io/caret/model-training-and-tuning.html) function for the two Elastic net methods (ENet1 and ENet2) and the [cv.glmnet](https://glmnet.stanford.edu/reference/cv.glmnet.html) function for LASSO, from [the caret](https://topepo.github.io/caret/) (v6.0.94) and [the glmnet](https://glmnet.stanford.edu/) (v.4.1.2) R package, respectively. For ENet1, both the parameter $\\alpha$ and $\\lambda$ were tuned by the `caret::train`, whereas the parameter $\\lambda$ was further tuned by the `glmnet::cv.glmnet` for ENet2. \n\nNext, based on the best fitted penalised regression models, a matrix of the $\\beta$ coefficient was examined to find the first set of predictors with non-zero $\\beta$ coefficients that satisfied a desired number of predictors. If the number of predictors with non-zero coefficients exceeded the desired number, the absolute values of coefficients were sorted in their decreasing order and only the desired number of predictors were selected with their highest absolute scores. \n\nFor the remaining methods, except [mSVM-RFE](https://github.com/johncolby/SVM-RFE) (see also @sec-cv-svm-rfe) which embedded a Recursive Feature Elimination (RFE) algorithm internally, we used the [`caret::rfe`](https://topepo.github.io/caret/recursive-feature-elimination.html#recursive-feature-elimination-via-caret) function by controlling the “sizes” parameter to have the corresponding models with the desired number of predictors. \n\n### `glParallel` {#sec-cv-glParallel}\nIn [glParallel](https://gitlab.developers.cam.ac.uk/ssg29/glparallel), a brute-force exhaustive search method, for a given number of predictors, it searched all possible combinations of predictors in multivariate regression models and picked the best model based on the highest predictive performance. \n\nFor example, glParallel trained a total of 2,380 models, which is the possible number of combinations having 4 predictors out of 17, and chose the best model based on the highest [Leave Pair Out Cross Validated (LPOCV)](https://pubmed.ncbi.nlm.nih.gov/24966219/) Area Under the ROC Curve (AUC), a version of optimism-corrected AUC. \n\n::: {.callout-note title=\"Install `glParallel`\"}\nYou need to download and install `glParallel` locally via the following `git` command:\n\n```{#lst-clone-glParallel .bash lst-cap=\"Code to download `glParallel`\"}\ngit clone https://gitlab.developers.cam.ac.uk/ssg29/glparallel.git static/R/glParallel\n```\n:::\n\nThen, prepare dataset to run `glParallel`.\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to prepare dataset for `glParallel`\"}\n#####################################################\n# make training dataset files for the CV glParallel #\n#####################################################\nlapply(names(li.fold), function(i){\n  message(\"fold=\",i)\n  # training set\n  my.index=li.fold[[i]]\n  my.file.name=file.path(\"glParallel/data\",paste(\"core17\",i,\"csv\",sep=\".\"))\n  fwrite(li.mat[[\"train\"]][[\"28wk\"]][my.index,], file=my.file.name)\n})\n# then run glParallel (see glParallel/RUN)\n\n####################################################\n# make training dataset files for final glParallel #\n####################################################\nfwrite(li.mat[[\"train\"]][[\"28wk\"]], file=\"glParallel/data/core17.final.csv\")\n```\n:::\n\n\n::: {.callout-note title=\"LPOCV-AUC\"}\nIn LPOCV-AUC, a model was fitted based on a given set of training samples except one pair of case-and-control, then the model was used to predict the outcome of the remaining pair. The LPOCV-AUC was calculated as the proportion of all pairwise combinations in which the predicted probability was greater for the case than for the control. \nThere is a helper function to calculate the LPOCV-AUC in [`glParallel`](https://gitlab.developers.cam.ac.uk/ssg29/glparallel/-/blob/main/lib/local.R?ref_type=heads#L68)\n:::\n\n### `mSVM-RFE` {#sec-cv-svm-rfe}\nThis method is from the (multiple) Support Vector Machine Recursive Feature Elimination [(mSVM-RFE)](https://github.com/johncolby/SVM-RFE).\n\n::: {.callout-note title=\"Install `SVM-RFE`\"}\nYou need to download nad install `SVM-RFE` locally via the following `git` command:\n\n```{#lst-clone-svm-rfe .bash lst-cap=\"Code to download `SVM-RFE`\"}\ngit clone https://github.com/johncolby/SVM-RFE.git static/R/SVM-RFE\n```\n:::\n\n## 5-Fold cross validation {#sec-5fold-cv}\n\nWe defined a series of helper functions to facilitate the whole process of CV more efficient.\n\n::: {.callout-tip title=\"`R` function `get_lasso_coef`\"}\nThis helper function runs [LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics)) and ranks features by their importance.\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to run Lasso and get non-zero coefficient\"}\n# returns: data.table(`method`,`fold`,`feature`,`score`,`rank`)\nget_lasso_coef<-function(x,my.fold,my.num=4){\n  #x isa `matrix` and should contain 'y' column\n  all.features<-colnames(x)[colnames(x)!=\"y\"]\n\n  #############\n  # run Lasso #\n  #############\n  set.seed(333) # set a random seed for a reproducibility\n  system.time(\n      cv.fit<-cv.glmnet(\n                  x= x[,all.features], \n                  y= x[,'y'], \n                  family=\"binomial\",\n                  alpha=1, # default (i.e. lasso)\n                  keep=T, # FALSE by default\n                  type.measure = \"auc\" #type.measure=\"class\" # default for 'binomial'\n      )\n  )\n\n  ############################################\n  # 1. select by lambda.min  & 2. lambda.1se #\n  ############################################\n  dt.foo<-lapply(c(\"lambda.min\",\"lambda.1se\"), function(my.lambda){\n    coeff1<-coef(cv.fit, s = my.lambda) %>% as.matrix #Extract coefficients from this glmnet object\n    nZero1<-coeff1[coeff1[,\"s1\"]!=0,,drop=F][-1,,drop=F] %>% nrow # the number of non-zero coeff\n    if(nZero1==0){\n      dt.foo<-data.table(\n                        method=my.lambda,\n                        fold=my.fold,\n                        `feature`=NA,\n                        score=NA)\n    }else{\n      coeff1[coeff1[,\"s1\"]!=0,,drop=F][-1,,drop=F] \n      coeff1[coeff1[,\"s1\"]!=0,,drop=F][-1,,drop=F] %>% as.data.table(keep.rownames=T) # return DT(rn,s1)\n      dt.foo<-data.table(\n                        method=my.lambda,\n                        fold=my.fold,\n                        coeff1[coeff1[,\"s1\"]!=0,,drop=F][-1,,drop=F] %>% as.data.table(keep.rownames=T))\n    }\n    setnames(dt.foo,c(\"method\",\"fold\",\"feature\",\"score\"))\n    dt.foo\n  }) %>% rbindlist\n\n  ####################\n  # 3. Lasso-pathway #\n  ####################\n  mat.beta <- cv.fit$glmnet.fit$beta %>% as.matrix\n  apply(mat.beta, 2, function(i){table(i!=0)[\"TRUE\"]})\n  my.lambdas<-apply(mat.beta, 2, function(i){table(i!=0)[\"TRUE\"]})>=my.num\n  this.index<-my.lambdas[my.lambdas & !is.na(my.lambdas)][1] %>% names # the first index >=my.num\n  if(is.na(this.index)){\n    NULL\n  }else{\n    this.index.num <- (strsplit(this.index,\"s\")[[1]][2] %>% as.integer) +1\n    nZero<-sum(mat.beta[,this.index]!=0, na.rm=T) # number of non-zero coefficient\n    #mat.beta[mat.beta[,this.index]!=0,this.index,drop=F]\n    dt.bar<-data.table(\n                      method=\"LASSO\",\n                      fold=my.fold,\n                      mat.beta[mat.beta[,this.index.num]!=0,this.index.num,drop=F] %>% as.data.table(keep.rownames=T)\n    ) # save as the above\n    setnames(dt.bar,c(\"method\",\"fold\",\"feature\",\"score\"))\n\n    if(nrow(dt.bar)>my.num){\n      dt.bar<-dt.bar[order(method,fold,-abs(score))][1:my.num]\n    }\n\n    dt.baz<-rbind(dt.foo, dt.bar)\n    dt.baz<-dt.baz[order(method,fold,-abs(score))][,rank:=1:.N,.(method,fold)]\n    return(dt.baz)\n  }\n} # end of get_lasso_coef\n```\n:::\n\n:::\n\n::: {.callout-tip title=\"`R` function `get_enet_coef`\"}\nThis helper function runs [Elastic net](https://en.wikipedia.org/wiki/Elastic_net_regularization) and rank features by their importance.\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to run ENet1 and ENet2 and get non-zero coefficients\"}\n# returns: data.table(`method`,`fold`,`feature`,`score`,`rank`)\nget_enet_coef<-function(x,my.fold,my.num=4){\n  #x isa `matrix` and should contain 'y' column\n  all.features<-colnames(x)[colnames(x)!=\"y\"]\n\n  cv.fit<-list()\n  ##########\n  # E: EN1 #\n  ##########\n  cl <- makePSOCKcluster(8) # No. of cores to use\n  registerDoParallel(cl)\n  set.seed(333) # set a random seed for a reproducibility\n  system.time(\n      cv.fit[[\"E\"]]<-caret::train(\n                              x= x[,all.features], \n                              y=factor(ifelse(x[,\"y\"]==1,'case','non_case'),levels=c(\"non_case\",\"case\")),\n                              method=\"glmnet\",\n                              family=\"binomial\",\n                              trControl = trainControl(method = \"cv\",\n                                                        summaryFunction = twoClassSummary,\n                                                        classProbs = TRUE,\n                                                        savePredictions = T,\n                                                        verboseIter = T,\n                                                        ),  # number =10 by default for \"cv\"\n                              tuneLength=10, # grid size: 10(alpha) * 10(lambda) \n      )\n  )\n  stopCluster(cl)\n\n  if(F){\n  varImp(cv.fit[[\"E\"]], useModel=T)\n  varImp(cv.fit[[\"E\"]], useModel=F, nonpara=F, scale=T)\n  predictors(cv.fit$E) # features used in the model\n  }\n\n  mat.beta<- cv.fit$E$finalModel$beta %>% as.matrix\n  my.lambdas<-apply(mat.beta, 2, function(i){table(i!=0)[\"TRUE\"]})>=my.num\n  this.index<-my.lambdas[my.lambdas & !is.na(my.lambdas)][1] %>% names\n  if(is.na(this.index)){\n    dt.foo<-NULL\n  }else{\n    this.index.num <- (strsplit(this.index,\"s\")[[1]][2] %>% as.integer) +1\n    #mat.beta[mat.beta[,this.index.num]!=0,this.index.num,drop=F] %>% as.data.table(keep.rownames=T)\n    dt.foo<-data.table(method=\"ENet1\",\n                      fold=my.fold,\n                      mat.beta[mat.beta[,this.index.num]!=0,this.index.num,drop=F] %>% as.data.table(keep.rownames=T)) # save as the above\n    setnames(dt.foo,c(\"method\",\"fold\",\"feature\",\"score\"))\n    if(nrow(dt.foo)>my.num){\n      dt.foo<-dt.foo[order(method,fold,-abs(score))][1:my.num]\n    }\n  }\n\n  ##########\n  # F: EN2 #\n  ##########\n  set.seed(333)\n  system.time(\n      cv.fit[[\"F\"]]<-cv.glmnet(\n                  x= x[,all.features], \n                  y= x[,\"y\"], # will be coerced to a factor if not (for binomial)\n                  family=\"binomial\",\n                  alpha=cv.fit$E$bestTune$alpha,\n                  keep=T, # FALSE by default\n                  type.measure = \"auc\" #type.measure=\"class\" # default for 'binomial'\n      )\n  )\n  #cv.fit$F$nzero\n  mat.beta2 <- cv.fit$F$glmnet.fit$beta %>% as.matrix\n  my.lambdas<-apply(mat.beta2, 2, function(i){table(i!=0)[\"TRUE\"]})>=my.num\n  this.index<-my.lambdas[my.lambdas & !is.na(my.lambdas)][1] %>% names\n  if(is.na(this.index)){\n    dt.bar<-NULL\n  }else{\n    this.index.num <- (strsplit(this.index,\"s\")[[1]][2] %>% as.integer) +1\n    dt.bar<-data.table(\n                        method=\"ENet2\",\n                        fold=my.fold,\n                        mat.beta2[mat.beta2[,this.index.num]!=0,this.index.num,drop=F] %>% as.data.table(keep.rownames=T)) # save as the above\n    setnames(dt.bar,c(\"method\",\"fold\",\"feature\",\"score\"))\n    if(nrow(dt.bar)>my.num){\n      dt.bar<-dt.bar[order(method,fold,-abs(score))][1:my.num]\n    }\n  }\n\n  dt.baz<-rbind(dt.foo,dt.bar)\n  if(!is.null(dt.baz)){\n    dt.baz<-dt.baz[order(method,fold,-abs(score))][,rank:=1:.N,.(method,fold)]\n  }\n  return(dt.baz)\n} # end of get_enet_coef\n```\n:::\n\n:::\n\n::: {.callout-tip title=\"`R` function `runRFE2`\"}\nThis helper function select desired number of features by using recursive feature elimination method via [`caret::rfe()`](https://topepo.github.io/caret/recursive-feature-elimination.html)\n\n::: {.cell lable='def-rfe'}\n\n```{.r .cell-code  code-summary=\"Code to run recursive feature elimination\"}\n# x: data matrix\n# my.method: \n# my.num: number of desired features\n# my.index: a list with elements for each external resampling iteration.\n# is.final: the final selected features if set true; oterwise at each fold level\n# returns: data.table(`method`,`fold`,`feature`,`score`,`rank`)\nrunRFE2 <-function(x, my.method=\"svmRadial\", my.num=4, my.index, is.final=F){\n  #x isa `matrix` and should contain 'y' column\n  all.features<-colnames(x)[colnames(x)!=\"y\"]\n\n  li.methods<-list(\n    `adaboost`=\"adaboost\",\n    `svmLinear`=\"svmLinear\",\n    `svmRadial`=\"svmRadial\",\n    `nnet`=\"nnet\",\n    `pcaNNet`=\"pcaNNet\",\n    `rfFuncs`=rfFuncs,\n    `nbFuncs`=nbFuncs,\n    )\n\n  my.fun<-li.methods[[my.method]]\n  if(is.list(my.fun)){\n    myFuncs<-my.fun\n  }else{\n    myFuncs<-caretFuncs\n  }\n  myFuncs$summary <- twoClassSummary\n\n  rfe.ctrl <- rfeControl(functions=myFuncs,\n                         method = \"cv\",\n                         #repeats =1, number = 10, # NB, index below\n                         #returnResamp=\"all\", # \"final\" by default\n                         saveDetails=T,\n                         verbose = TRUE,\n                         index = my.index #a list with elements for each external resampling iteration.\n                                          #Each list element is the sample rows used for training at\n                                          #that iteration.\n  )\n\n  tr.ctrl <- trainControl(method = \"cv\",\n                          #repeats =1, number = 10, # NB, index below\n                          summaryFunction = twoClassSummary,\n                          classProbs = TRUE,\n                          savePredictions = T,\n                          verboseIter = T,\n                          index = my.index #a list with elements for each external resampling iteration.\n                                            #Each list element is the sample rows used for training at\n                                            #that iteration.\n  )\n\n  # run REF via caret::ref #\n  cl <- makePSOCKcluster(8) # No. of cores to use\n  registerDoParallel(cl)\n  set.seed(333) # set a random seed for a reproducibility\n  cv.rfe<-caret::rfe(\n                     x=as.data.frame(x[,all.features]),\n                     y=factor(ifelse(x[,\"y\"]==1,'case','non_case'),levels=c(\"non_case\",\"case\")),\n                     sizes = my.num, #2^(2:4), # default \n                     metric=\"ROC\",\n                     rfeControl=rfe.ctrl,\n                     method=my.method, # feed it to 'train'\n                     tuneLength = 5, #ifelse(trControl$method == \"none\", 1, 3)\n                     trControl=tr.ctrl # feed it to 'train'\n  )\n  stopCluster(cl)\n\n  dt.foo<-data.table(`method`=my.method,cv.rfe$variables)\n  if(is.final){\n    dt.bar<-data.table(`method`=my.method,\n                       `fold`=\"final\",\n                       `feature`=cv.rfe$optVariables[1:my.num],\n                       `score`=NA,\n                       `rank`=1:my.num)\n  }else{\n    dt.bar<-dt.foo[Variables==cv.rfe$optsize][order(Resample,-Overall)][,.SD[1:my.num],.(method,Resample)][,rank:=1:.N,.(method,Resample)][,.(method,fold=Resample,feature=var,score=Overall,rank)]\n  }\n\n  return(dt.bar)\n}\n```\n:::\n\n:::\n\n::: {.callout-tip title=\"`R` function `get_cv_glm`\"}\nThis helper function extracts the predictive performance of the training model from a given fold tested using held-out samples during kCV.\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to extract the stat of the training model given the fold ID from the 5-fold CV with 5 repetitions\"}\n# x: matrix dataset (train/test at the same time, separated by my.index which is the training)\n# my.fold: fold ID\n# my.index: the training index of `x` to subset where the model should be built\n# my.feature: features of interests\nget_cv_glm<-function(x=li.mat[[\"train\"]][[\"28wk\"]],my.fold,my.index,my.feature){\n  mat.tr<-x[my.index,] # index of the training\n  df.mat.tr<-mat.tr[,c(my.feature,'y')] %>% as.data.frame  # training set\n\n  ############################################\n  # fit the model using the training dataset #\n  ############################################\n  my.model<-glm(y~. , data = df.mat.tr, family = \"binomial\")\n\n  # ROC from the training fold\n  my.roc <-pROC::roc(response=df.mat.tr$y, predictor=fitted(my.model),quite=T,ci=T)\n\n  # LPOCV from the training fold\n  LPOCV.boot<-boot::boot(data=df.mat.tr, statistic=get_LPOCV_boot,R=100,parallel=\"multicore\",ncpus=10)\n  LPOCV.ci<-boot::boot.ci(LPOCV.boot,type=\"perc\")\n\n  # the whole dataset were training set, i.e. no test\n  if(length(my.index)==nrow(x)){\n    cbind(\n      data.table(\n                `fold`=my.fold,\n                `predictor`=paste(my.feature,collapse=\",\")\n                ),\n      data.table(\n                `AIC`=my.model$aic,\n                `BIC`=BIC(my.model),\n                `AUC`=my.roc$ci[2]*100, \n                `AUC_lo`=my.roc$ci[1]*100, \n                `AUC_hi`=my.roc$ci[3]*100,\n                `LPOCV`=LPOCV.boot$t0,\n                `LPOCV_lo`=LPOCV.ci$percent[4],\n                `LPOCV_hi`=LPOCV.ci$percent[5]\n                )\n    )\n  }else{\n    #################################################\n    # now, predict the outcome of the held-out data #\n    # using the model from the training dataset     #\n    #################################################\n    mat.test<-x[-my.index,]  \n    df.mat.test<-mat.test[,c(my.feature,'y')] %>% as.data.frame # held-out\n\n    my.prob<-predict.glm(my.model, newdata=df.mat.test, type=\"response\") \n    my.roc.test <- pROC::roc(response=df.mat.test$y, predictor=my.prob,quiet=T,ci=T)\n    LPOCV.boot.test<-boot::boot(data=df.mat.test, statistic=get_LPOCV_boot,R=100,parallel=\"multicore\",ncpus=20)\n    # deal with failed boot result\n    if(is.numeric(LPOCV.boot.test$t)){\n      LPOCV.ci.test<-boot::boot.ci(LPOCV.boot.test,type=\"perc\")\n      LPOCV_test_lo=LPOCV.ci.test$percent[4]\n      LPOCV_test_hi=LPOCV.ci.test$percent[5]\n    }else{\n      LPOCV_test_lo=NA\n      LPOCV_test_hi=NA\n    }\n    # return the following table\n    cbind(\n      data.table(\n                `fold`=my.fold,\n                `predictor`=paste(my.feature,collapse=\",\")\n                ),\n      data.table(\n                `AIC`=my.model$aic,\n                `BIC`=BIC(my.model),\n                `AUC`=my.roc$ci[2]*100, \n                `AUC_lo`=my.roc$ci[1]*100, \n                `AUC_hi`=my.roc$ci[3]*100,\n                `LPOCV`=LPOCV.boot$t0,\n                `LPOCV_lo`=LPOCV.ci$percent[4],\n                `LPOCV_hi`=LPOCV.ci$percent[5],\n                `AUC_test`=my.roc.test$ci[2]*100, \n                `AUC_test_lo`=my.roc.test$ci[1]*100, \n                `AUC_test_hi`=my.roc.test$ci[3]*100,\n                `LPOCV_test`=LPOCV.boot.test$t0,\n                `LPOCV_test_lo`=LPOCV_test_lo,\n                `LPOCV_test_hi`=LPOCV_test_hi\n                )\n    )\n  }\n}\n```\n:::\n\n:::\n\n::: {.callout-tip title=\"`R` function `get_cv_glm2`\"}\nThis helper function extracts the basic statistic (e.g. AIC, BIC, and AUC etc) of the training model for a given fold during kCV.\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to extract the predictive performance of the training model given the fold ID from the 5-fold CV with 5 repetitions\"}\n# x: the dataset where the model should be tested on (i.e. the test set)\n# my.model: the model from the training \n# my.feature: features of interests\nget_cv_glm2<-function(x=li.mat[[\"test\"]][[\"28wk\"]],my.fold, my.model,my.feature){\n    df.mat.test<-x[,c(my.feature,'y')] %>% as.data.frame # test (validation) dataset\n\n    #my.prob<-predict.glm(my.model, newdata=df.mat.test, type=\"response\") \n    my.prob<-predict(my.model, newdata=df.mat.test, type=\"response\") \n    my.roc.test <- pROC::roc(response=df.mat.test$y, predictor=my.prob,quiet=T,ci=T)\n    LPOCV.boot.test<-boot::boot(data=df.mat.test, statistic=get_LPOCV_boot,R=100,parallel=\"multicore\",ncpus=20)\n    # deal with failed boot result\n    if(is.numeric(LPOCV.boot.test$t)){\n      LPOCV.ci.test<-boot::boot.ci(LPOCV.boot.test,type=\"perc\")\n      LPOCV_test_lo=LPOCV.ci.test$percent[4]\n      LPOCV_test_hi=LPOCV.ci.test$percent[5]\n    }else{\n      LPOCV_test_lo=NA\n      LPOCV_test_hi=NA\n    }\n\n    # return the following table\n    cbind(\n      data.table(\n                `fold`=my.fold,\n                `predictor`=paste(my.feature,collapse=\",\")\n                ),\n      data.table(\n                `AUC_test`=my.roc.test$ci[2]*100, \n                `AUC_test_lo`=my.roc.test$ci[1]*100, \n                `AUC_test_hi`=my.roc.test$ci[3]*100,\n                `LPOCV_test`=LPOCV.boot.test$t0,\n                `LPOCV_test_lo`=LPOCV_test_lo,\n                `LPOCV_test_hi`=LPOCV_test_hi,\n                 `AIC`=my.model$aic,\n                 `BIC`=BIC(my.model)\n                )\n    )\n}\n```\n:::\n\n:::\n\nHaving defined those helper functions, we are now ready to proceed 5-fold CV with 5 repetitions.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to run 11 ML methods in 5-fold CV with 5-repetitions\"}\n## \n## Training on based on 5-fold CV\n##\nmy.RData<-file.path(\"RData/dl.kcv.core17.RData\")\nif(file.exists(my.RData)){\n  load(my.RData)\n}else{\n  library(e1071)\n  source('SVM-RFE/msvmRFE.R')\n\n  li.methods<-list(\n    `adaboost`=\"adaboost\",\n    `svmLinear`=\"svmLinear\",\n    `svmRadial`=\"svmRadial\",\n    `nnet`=\"nnet\",\n    `pcaNNet`=\"pcaNNet\",\n    `rfFuncs`=rfFuncs,\n    `nbFuncs`=nbFuncs\n    )\n\n  #|Num: 6 Method: LASSO\n  # Fold5.Rep5\n  #Error in mat.beta[, this.index] : subscript out of bounds\n  li.num<-list(`F2`=2,`F3`=3,`F4`=4,`F5`=5,`F6`=6)\n  dl.kcv<-lapply(li.num, function(my.num){\n    # 1. glParallel\n    message(paste(\"Num:\",my.num,\"Method: glParallel\"))\n    my.pattern=paste0(\"^core17\\\\.Fold[[:alnum:]]\\\\.Rep[[:alnum:]]\\\\.best\",my.num)\n    dt.input<-data.table(\n                    foo=list.files(\"glParallel/result\",pattern=my.pattern),\n                    files=list.files(\"glParallel/result\",pattern=my.pattern,full.names=T)\n                    )[,c(\"foo1\",\"bar1\"):=tstrsplit(foo,\"\\\\.\",keep=c(2,3))][,fold:=paste(foo1,bar1,sep=\".\")][,c(\"foo\",\"foo1\",\"bar1\"):=NULL]\n\n    dt.cv.glp <-apply(dt.input, 1, function(i){\n              my.fold<-i[[\"fold\"]]\n              my.feature<-fread(i[\"files\"])[1][[\"Best proteins\"]] %>% strsplit(\",\") %>% unlist\n              data.table(method=\"glParallel\",fold=my.fold,feature=my.feature,score=NA,rank=NA)\n              #cbind(`fold`=i[[\"fold\"]],fread(i[\"files\"])[1])\n    }) %>% rbindlist\n\n    # 2. Lasso\n    # one multinomial or binomial class has fewer than 8  observations; dangerous ground\n    dt.cv.lasso<-lapply(names(li.fold), function(my.fold){\n      message(paste(\"Num:\",my.num,\"Method: LASSO, Fold:\",my.fold))\n      my.tr.index<-li.fold[[my.fold]] # index of training \n      x<-li.mat[[\"train\"]][[\"28wk\"]][my.tr.index,] # the training dataset\n      get_lasso_coef(x, my.fold, my.num=my.num) \n    }) %>% rbindlist\n\n    # 3. ElasticNet\n    # warnings(): one multinomial or binomial class has fewer than 8  observations; dangerous ground\n    dt.cv.enet<-lapply(names(li.fold), function(my.fold){\n      message(paste(\"Num:\",my.num,\"Method: ENET, Fold:\",my.fold))\n      my.tr.index<-li.fold[[my.fold]] # index of training \n      x<-li.mat[[\"train\"]][[\"28wk\"]][my.tr.index,] # the training dataset \n      get_enet_coef(x, my.fold, my.num=my.num) \n    }) %>% rbindlist\n\n    # 4. mSVM-RFE\n    dt.cv.svm<-lapply(names(li.fold), function(my.fold){\n      message(paste(\"Num:\",my.num,\"Method: mSVM-RFE, Fold:\",my.fold))\n      my.tr.index<-li.fold[[my.fold]] # index of training \n      x<-li.mat[[\"train\"]][[\"28wk\"]][my.tr.index,] # the training dataset \n      set.seed(333)\n      ranked.features<-colnames(x)[-1][svmRFE(x, k=5, halve.above=100)][1:my.num] # only top x ranked features\n      data.table(method=\"mSVM-RFE\",`fold`=my.fold,feature=ranked.features, score=NA,rank=1:length(ranked.features))\n    }) %>% rbindlist\n\n    # 5-10. Other methods via RFE\n    dt.cv.rfe<-lapply(names(li.methods), function(my.method){\n              # runRFE2 for each repetition\n              lapply(paste0(\"Rep\",1:5), function(iRep){\n                this.fold<-paste(paste0(\"Fold\",1:5),iRep,sep=\".\") # 5-fold for this repetition\n                message(paste(\"Num:\",my.num,\"Method:\",my.method, \"Fold:\",this.fold))\n\n                runRFE2(x=li.mat[[\"train\"]][[\"28wk\"]], my.method=my.method, my.num=my.num, my.index=li.fold[this.fold])\n              }) %>% rbindlist\n    }) %>% rbindlist\n\n    rbind(dt.cv.glp, dt.cv.lasso[method==\"LASSO\"], dt.cv.enet, dt.cv.svm, dt.cv.rfe)\n  }) # end of dl.kcv\n\n  save(dl.kcv, file=my.RData)\n}\n\n##\n##\nmy.RData<-file.path(\"RData/dl.kcv.result.core17.RData\")\nif(file.exists(my.RData)){\n  load(my.RData)\n}else{\n  # for each number of feature: F2, F3, F4, F5, F6\n  dl.kcv.result<-parallel::mclapply(dl.kcv, function(dt.kcv){\n    # features by method and fold\n    dt.foo<-dt.kcv[order(method,fold,feature)][,.(.N,features=paste(feature,collapse=\",\")),.(method,fold)]\n    my.num<-dt.foo[,unique(N)]\n\n    # features by method, fold and features\n    dt.bar<-dt.kcv[order(method,fold,feature)][,.(.N,features=paste(feature,collapse=\",\")),.(method,fold)][,.(.N,methods=paste(method,collapse=\",\")),.(fold,features)][order(fold,-N)]\n\n    # get the CV-LPOCV (or CV-AUC) across 25 folds (i.e. 5-Fold-CV * 5 Rep) \n    dl.bar<-split(dt.bar, dt.bar$fold) # by each fold\n    dt.kcv.result<-parallel::mclapply(dl.bar, function(dt.baz){\n      my.fold<-dt.baz[,.N,fold]$fold\n      my.index<-li.fold[[my.fold]] # index of training\n\n      # for each list of features in this fold\n      lapply(dt.baz$features, function(i){\n        message(paste(\"Num:\",my.num,\", Fold:\",my.fold, \", Features:\",i))\n        my.feature <- i %>% strsplit(\",\") %>% unlist\n        get_cv_glm(x=li.mat[[\"train\"]][[\"28wk\"]],my.fold,my.index,my.feature)\n      }) %>% rbindlist # merge all features\n    },mc.cores=1) %>% rbindlist # merge all fold\n\n    merge(dt.foo, dt.kcv.result, by.x=c(\"fold\",\"features\"), by.y=c(\"fold\",\"predictor\"))\n  },mc.cores=1) # parallel by the No. of features\n  save(dl.kcv.result, file=my.RData)\n}\n```\n:::\n\n\nHaving selected a set of predictors for each of the 11 ML methods, a logistic regression model was fitted on the training fold based on the selected predictors, and its predictive performance, i.e. the AUC, was calculated using the remaining held-out test fold. As the 5-fold CV was repeated 5 times, the 25 cross-validated AUCs were averaged by taking the mean AUC. This procedure was repeated from a selection of 2- to 6-predictor models, i.e. 5 times, so the cross-validated AUCs were again averaged by taking the mean values of AUCs. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to extract the final selected features from each ML method and fit a regression model and test its performance.\"}\nmy.RData<-file.path(\"RData/dl.final.models.core17.RData\")\nif(file.exists(my.RData)){\n  load(my.RData)\n}else{\n  library(e1071)\n  source('SVM-RFE/msvmRFE.R')\n\n  li.methods<-list(\n    `svmLinear`=\"svmLinear\",\n    `svmRadial`=\"svmRadial\",\n    `nnet`=\"nnet\",\n    `pcaNNet`=\"pcaNNet\",\n    `rfFuncs`=rfFuncs,\n    `nbFuncs`=nbFuncs\n    )\n\n  li.num<-list(`F2`=2,`F3`=3,`F4`=4,`F5`=5,`F6`=6)\n  x<-li.mat[[\"train\"]][[\"28wk\"]]\n\n  dl.final.models<-lapply(li.num, function(my.num){\n    # 1. glParallel\n    message(paste(\"Num:\",my.num,\"Method: glParallel\"))\n    my.pattern=paste0(\"^core17\\\\.final\\\\.best\",my.num)\n    dt.input<-data.table(\n                    foo=list.files(\"glParallel/result\",pattern=my.pattern),\n                    files=list.files(\"glParallel/result\",pattern=my.pattern,full.names=T)\n                    )[,c(\"foo1\",\"bar1\"):=tstrsplit(foo,\"\\\\.\",keep=c(2,3))][,fold:=paste(foo1,bar1,sep=\".\")][,c(\"foo\",\"foo1\",\"bar1\"):=NULL]\n\n    dt.glp <-apply(dt.input, 1, function(i){\n              my.fold<-i[[\"fold\"]]\n              my.feature<-fread(i[\"files\"])[1][[\"Best proteins\"]] %>% strsplit(\",\") %>% unlist\n              data.table(method=\"glParallel\",fold=my.fold,feature=my.feature,score=NA,rank=NA)\n              #cbind(`fold`=i[[\"fold\"]],fread(i[\"files\"])[1])\n    }) %>% rbindlist\n\n    # 2. Lasso\n    message(paste(\"Num:\",my.num,\"Method: LASSO\"))\n    dt.lasso<-get_lasso_coef(x=x, \"final\", my.num=my.num)\n\n    # 3. ElasticNet\n    message(paste(\"Num:\",my.num,\"Method: ENET\"))\n    dt.enet<-get_enet_coef(x=x, \"final\", my.num=my.num)\n\n    # 4. mSVM-RFE\n    message(paste(\"Num:\",my.num,\"Method: mSVM-RFE\"))\n    set.seed(333)\n    ranked.features<-colnames(x)[-1][svmRFE(x, k=5, halve.above=100)][1:my.num] # only top 4 ranked features\n    dt.svm<-data.table(method=\"mSVM-RFE\",`fold`=\"final\",feature=ranked.features, score=NA, rank=1:length(ranked.features))\n\n    # 5-10. Other methods via RFE: \"svmLinear\" \"svmRadial\" \"nnet\"      \"pcaNNet\"   \"rfFuncs\"   \"nbFuncs\"\n    dt.rfe<-lapply(names(li.methods), function(my.method){\n              message(paste(\"Num:\",my.num,\"Method:\",my.method))\n              runRFE2(x=x, my.method=my.method, my.num=my.num, my.index=li.fold.final, is.final=T)\n    }) %>% rbindlist\n\n    # compile all the final models #\n    rbind(dt.glp, dt.lasso[method==\"LASSO\"], dt.enet, dt.svm, dt.rfe)[order(method,feature)]\n  }) # end of dl.final.models\n  save(dl.final.models, file=my.RData)\n} # end of if\n\nmy.RData<-file.path(\"RData/dl.final.result.core17.RData\")\nif(file.exists(my.RData)){\n  load(my.RData)\n}else{\n  mat.tr<-li.mat[[\"train\"]][[\"28wk\"]] # training model\n\n  dl.final.result<-lapply(dl.final.models, function(dt.model){\n    dt.final.model<-dt.model[,.(.N,features=paste(feature,collapse=\",\")),method][order(features)]\n    dt.final<-dt.final.model[,.(.N,methods=paste(method,collapse=',')),features]\n\n    #######################################################################\n    # get LPOCV/AUC from the preterm dataset (NB, 28wk-preterm: training) #\n    #######################################################################\n    dt.final.result<-lapply(dt.final$methods, function(my.methods){\n                          ############################################\n                          # fit the model using the training dataset #\n                          ############################################\n                          my.feature<-dt.final[methods==my.methods]$features %>% strsplit(\",\") %>% unlist\n                          df.mat.tr<-mat.tr[,c(my.feature,'y')] %>% as.data.frame  # training set\n                          my.model<-glm(y~. , data = df.mat.tr, family = \"binomial\")\n\n                          ## preterm (NB, 28wk: training dataset where the model was built)\n                          dt.foo1<-lapply(c(\"12wk\",\"20wk\",\"28wk\"), function(my.GA){\n                            message(paste(\"preterm\",my.methods,my.GA,sep=\":\"))\n                            x<-li.mat[[\"train\"]][[my.GA]]\n                            my.fold<-paste0(my.GA,\"(preterm)\")\n                            cbind(`methods`=my.methods,\n                                  get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                            )\n                          }) %>% rbindlist\n\n                          ## term (validation)\n                          dt.foo2<-lapply(c(\"12wk\",\"20wk\",\"28wk\",\"36wk\"), function(my.GA){\n                            message(paste(\"term\",my.methods,my.GA,sep=\":\"))\n                            x<-li.mat[[\"test\"]][[my.GA]]\n                            my.fold<-paste0(my.GA,\"(term)\")\n                            cbind(`methods`=my.methods,\n                                  get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                            )\n                          }) %>% rbindlist\n                          \n                          ## Munchel \n                          message(paste(\"Munchel\",my.methods,sep=\":\"))\n                          x<-li.mat[[\"munchel\"]]\n                          my.fold<-\"Munchel\"\n                          dt.foo3<-cbind(`methods`=my.methods,\n                                  get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                          )\n\n                          rbind(dt.foo1,dt.foo2,dt.foo3)\n                      }) %>% rbindlist\n    dt.final.result<-dt.final.result[order(fold,-AUC_test)]\n    dt.final.result\n  })\n  save(dl.final.result, file=my.RData)\n}\n```\n:::\n\n\n## Internal and external validation {#sec-validation}\n\nHaving identified the winning method (as shown in @fig-fig3 A), it was applied to choose 2 to 10 predictors using the whole 28wkGA samples of the discovery dataset and the selected predictors were used to fit multivariate logistic regression models using the same training dataset (@fig-fig3 B). Finally, we evaluated the predictive performance of those 2- to 10-predictor logistic regression models using the term validation cohort and the external Munchel dataset (as shown in @fig-fig4).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Code to run internal and external validations for 2-10 predictors chosen by the winning method of 5-fold CV.\"}\nmy.RData<-file.path(\"RData/dl.enet.models.core17.RData\")\nif(file.exists(my.RData)){\n  load(my.RData)\n}else{\n  li.num<-2:10 %>% as.list\n  names(li.num)=paste0(\"F\",2:10)\n\n  x<-li.mat[[\"train\"]][[\"28wk\"]]\n\n  dl.enet.models<-lapply(li.num, function(my.num){\n    # 2. Lasso\n    message(paste(\"Num:\",my.num,\"Method: LASSO\"))\n    dt.lasso<-get_lasso_coef(x=x, \"final\", my.num=my.num)\n\n    # 3. ElasticNet\n    message(paste(\"Num:\",my.num,\"Method: ENET\"))\n    dt.enet<-get_enet_coef(x=x, \"final\", my.num=my.num)\n\n    # compile all the final models #\n    rbind(dt.lasso[method==\"LASSO\"], dt.enet)[order(method,feature)]\n  }) # end of dl.final.models\n  save(dl.enet.models, file=my.RData)\n} # end of if\n\n##\n## ENet and LASSO only using Discovery and Validation datasets\n## \nmy.RData<-file.path(\"RData/dl.enet.result.core17.RData\")\nif(file.exists(my.RData)){\n  load(my.RData)\n}else{\n  mat.tr<-li.mat[[\"train\"]][[\"28wk\"]] # training model\n\n  dl.enet.result<-lapply(dl.enet.models, function(dt.model){\n    dt.final.model<-dt.model[,.(.N,features=paste(feature,collapse=\",\")),method][order(features)]\n    dt.final<-dt.final.model[,.(.N,methods=paste(method,collapse=',')),features]\n    #######################################################################\n    # get LPOCV/AUC from the preterm dataset (NB, 28wk-preterm: training) #\n    #######################################################################\n    dt.final.result<-lapply(dt.final$methods, function(my.methods){\n                          ############################################\n                          # fit the model using the training dataset #\n                          ############################################\n                          my.feature<-dt.final[methods==my.methods]$features %>% strsplit(\",\") %>% unlist\n                          df.mat.tr<-mat.tr[,c(my.feature,'y')] %>% as.data.frame  # training set\n                          my.model<-glm(y~. , data = df.mat.tr, family = \"binomial\")\n\n                          ## preterm (NB, 28wk: training dataset where the model was built)\n                          dt.foo1<-lapply(c(\"12wk\",\"20wk\",\"28wk\"), function(my.GA){\n                            message(paste(\"preterm\",my.methods,my.GA,sep=\":\"))\n                            x<-li.mat[[\"train\"]][[my.GA]]\n                            my.fold<-paste0(my.GA,\"(preterm)\")\n                            cbind(`methods`=my.methods,\n                                  get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                            )\n                          }) %>% rbindlist\n\n                          ## term (validation)\n                          dt.foo2<-lapply(c(\"12wk\",\"20wk\",\"28wk\",\"36wk\"), function(my.GA){\n                            message(paste(\"term\",my.methods,my.GA,sep=\":\"))\n                            x<-li.mat[[\"test\"]][[my.GA]]\n                            my.fold<-paste0(my.GA,\"(term)\")\n                            cbind(`methods`=my.methods,\n                                  get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                            )\n                          }) %>% rbindlist\n                          \n                          ## Munchel \n                          message(paste(\"Munchel\",my.methods,sep=\":\"))\n                          x<-li.mat[[\"munchel\"]]\n                          my.fold<-\"Munchel\"\n                          dt.foo3<-cbind(`methods`=my.methods,\n                                  get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                          )\n\n                          rbind(dt.foo1,dt.foo2,dt.foo3)\n                      }) %>% rbindlist\n    dt.final.result<-dt.final.result[order(fold,-AUC_test)]\n    dt.final.result\n  }) # end of dl.enet.models\n  save(dl.enet.result, file=my.RData)\n}\n\n#\n# The final best models\n#\nmy.RData<-file.path(\"RData/dt.best.result.core17.RData\")\nif(file.exists(my.RData)){\n  load(my.RData)\n}else{\n  my.targets<-c(\"LEP\",\"PAPPA2\",\"LEP,PAPPA2\",\n                \"LEP,LY6G6D,PAPPA2\" # best performing LASSO 3-mRNA model\n                )\n\n  mat.tr<-li.mat[[\"train\"]][[\"28wk\"]] # training model\n  mat.tr<-cbind(mat.tr, \"LEP_PAPPA2\"=mat.tr[,\"LEP\"] * mat.tr[,\"PAPPA2\"])\n\n  #######################################################################\n  # get LPOCV/AUC from the preterm dataset (NB, 28wk-preterm: training) #\n  #######################################################################\n  my.targets<-\"LEP_PAPPA2\"\n\n  dt.best.result<-lapply(my.targets, function(my.proteins){\n                        ############################################\n                        # fit the model using the training dataset #\n                        ############################################\n                        my.feature<-strsplit(my.proteins,\",\") %>% unlist\n                        df.mat.tr<-mat.tr[,c(my.feature,'y')] %>% as.data.frame  # training set\n                        my.model<-glm(y~. , data = df.mat.tr, family = \"binomial\")\n\n                        ## preterm (NB, 28wk: training dataset where the model was built)\n                        dt.foo1<-lapply(c(\"12wk\",\"20wk\",\"28wk\"), function(my.GA){\n                          message(paste(\"preterm\",my.GA,my.proteins,sep=\":\"))\n                          x<-li.mat[[\"train\"]][[my.GA]]\n                          x<-cbind(x, \"LEP_PAPPA2\"=x[,\"LEP\"] * x[,\"PAPPA2\"])\n                          my.fold<-paste0(my.GA,\"(preterm)\")\n                          get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                        }) %>% rbindlist\n\n                        ## term (validation)\n                        dt.foo2<-lapply(c(\"12wk\",\"20wk\",\"28wk\",\"36wk\"), function(my.GA){\n                          message(paste(\"term\",my.GA,my.proteins,sep=\":\"))\n                          x<-li.mat[[\"test\"]][[my.GA]]\n                          x<-cbind(x, \"LEP_PAPPA2\"=x[,\"LEP\"] * x[,\"PAPPA2\"])\n                          my.fold<-paste0(my.GA,\"(term)\")\n                          get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                        }) %>% rbindlist\n                        \n                        ## Munchel \n                        message(paste(\"Munchel\",my.proteins,sep=\":\"))\n                        x<-li.mat[[\"munchel\"]]\n                        x<-cbind(x, \"LEP_PAPPA2\"=x[,\"LEP\"] * x[,\"PAPPA2\"])\n                        my.fold<-\"Munchel\"\n                        dt.foo3<-get_cv_glm2(x=x,my.fold=my.fold,my.model=my.model,my.feature=my.feature)\n                        rbind(dt.foo1,dt.foo2,dt.foo3)\n                    }) %>% rbindlist\n  save(dt.best.result, file=my.RData)\n}\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}